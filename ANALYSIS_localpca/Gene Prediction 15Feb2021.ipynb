{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import time\n",
    "import pyracular\n",
    "import random\n",
    "from biobeaker.utils import get_angles, positional_encoding\n",
    "from biobeaker import BEAKER\n",
    "\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "from umap import UMAP\n",
    "import plotly.express as px\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    Lambda,\n",
    "    Subtract,\n",
    "    Input,\n",
    "    Concatenate,\n",
    "    AveragePooling1D,\n",
    "    Reshape,\n",
    "    GRU,\n",
    "    Bidirectional,\n",
    "    Dropout,\n",
    "    LSTM,\n",
    "    Conv1D,\n",
    "    Conv2D,\n",
    "    LocallyConnected1D,\n",
    "    Conv1DTranspose,\n",
    ")\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "from lib.useful_windows import (\n",
    "    calc_kmer_numeric_tuple,\n",
    "    convert_tuple_to_string,\n",
    "    calc_distance,\n",
    "    convert_tuple_to_np,\n",
    "    cos_sim,\n",
    "    convert_string_to_nparray,\n",
    "    convert_string_to_nparray_tuple,\n",
    ")\n",
    "from lib.bert_inspired import (\n",
    "    get_angles,\n",
    "    positional_encoding,\n",
    "    fasta_generator,\n",
    "    discriminator_layer,\n",
    "    point_wise_feed_forward_network,\n",
    "    gff3_type_classification_layer,\n",
    ")\n",
    "from TransformerModelPosConcat_12Oct import Transformer, CustomSchedule, ffn\n",
    "from collections import defaultdict\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chr2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyracular.get_headers_from_sfasta(\"Vvulg_chr2.sfasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "k = 21\n",
    "window_size = 32\n",
    "num_layers = 8\n",
    "embedding_dims = 32\n",
    "output_dims = 128 # Output dims are also internal dims!\n",
    "intermediate_dims = 256\n",
    "num_heads = 8\n",
    "dropout_rate = 0.15\n",
    "max_positions = 512\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = BEAKER(num_layers, embedding_dims, output_dims, num_heads, intermediate_dims, max_positions,\n",
    "                          dropout=dropout_rate, attention_dropout=dropout_rate, activation=tfa.activations.mish)\n",
    "\n",
    "# Magic embeddings \n",
    "# \n",
    "# Kmer -> DNA Embedding\n",
    "# Where kmer1 (k1) and kmer2 (k2)\n",
    "# manhattan_distance(k1, k2) =~ alignment_distance(k1, k2)\n",
    "\n",
    "magic = Dense(embedding_dims, \n",
    "                activation=tf.nn.swish, \n",
    "                name=\"Magic\", \n",
    "                use_bias=False, \n",
    "                trainable=False,\n",
    "                dtype=tf.float32)\n",
    "\n",
    "magic.build((window_size+1,k*5))\n",
    "\n",
    "#Load up the weights\n",
    "weights = np.load(\"weights/weights_wide_singlelayer_k21_3Aug2020model_21_dims_32_epochs256.npy\", allow_pickle=True)\n",
    "magic.set_weights([weights[0][0]])\n",
    "\n",
    "transformer.load_weights(\"beaker_medium_tripleloss\")\n",
    "\n",
    "cls = np.asarray([[1] * 105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = np.asarray([[1] * 105])\n",
    "gene_token = np.asarray([[1,0,1] * 35])\n",
    "end_of_query_token = np.asarray([[0, 1, 1] * 35])\n",
    "\n",
    "#Classes are:\n",
    "# 5 long\n",
    "# 0 is query start (for decoder) [1, 0, 0, 0, 0, 0]\n",
    "# 1 is not a gene [0, 1, 0, 0, 0, 0]\n",
    "# 2 is gene start [0, 0, 1, 0, 0, 0]\n",
    "# 3 is gene [0, 0, 0, 1, 0, 0]\n",
    "# 4 is end of gene [0, 0, 0, 0, 1, 0]\n",
    "# 5 is end of decoder output [0, 0, 0, 0, 0, 1]\n",
    "\n",
    "n_classes = 5\n",
    "\n",
    "def gen():\n",
    "    fasta = pyracular.Gff3KmerGenerator(\n",
    "        k, \"Dmel.sfasta\", window_size, \"Dmel.gff3\", True\n",
    "    )\n",
    "    types = fasta.types()\n",
    "    gene_index = types.index(\"gene_Plus\")\n",
    "    minus_gene_index = types.index(\"gene_Minus\")\n",
    "    for i in fasta:\n",
    "        if i[\"rc\"]:\n",
    "            gi = minus_gene_index\n",
    "        else:\n",
    "            gi = gene_index\n",
    "        gene_classifications = []\n",
    "        #gene_classifications.append([1,0,0,0,0,0]) # Start token\n",
    "        gene_classifications.append(0)\n",
    "        gc_count = []\n",
    "        \n",
    "        for x in i[\"classifications\"]:\n",
    "            gc_count.append(x[gi])\n",
    "            if x[gi] == 1:\n",
    "                #gene_classifications.append([0,0,0,1,0,0]) # Is a gene\n",
    "                gene_classifications.append(3)\n",
    "            else:\n",
    "                #gene_classifications.append([0,1,0,0,0,0]) # Not a gene\n",
    "                gene_classifications.append(1)\n",
    "        total = np.sum(gc_count)\n",
    "        \n",
    "        #gene_classifications.append([0,0,0,0,0,1]) # End token\n",
    "        gene_classifications.append(5)\n",
    "\n",
    "        # TODO: Bad attempt at balancing\n",
    "        if total == 0 or total == window_size:\n",
    "            continue\n",
    "\n",
    "        sample_weight = (0.5 - (np.abs((total / window_size) - 0.5))) / 0.5\n",
    "        #        if sample_weight <= 0.5:\n",
    "        #            continue\n",
    "        \n",
    "        for n in range(1, window_size+1):\n",
    "            prev = gene_classifications[n-1]\n",
    "            future = gene_classifications[n+1]\n",
    "            cur = gene_classifications[n]\n",
    "            \n",
    "            if cur == 3 and prev == 1:\n",
    "                gene_classifications[n] = 2; # Gene start\n",
    "            elif prev == 3 and future == 1:\n",
    "                gene_classifications[n] = 4\n",
    "        \n",
    "        #kmers = np.concatenate([gene_token, i['kmers'], end_of_query_token])\n",
    "        kmers = np.concatenate([cls, i['kmers']])\n",
    "        gene_classifications = tf.one_hot(gene_classifications, n_classes)\n",
    "        yield kmers, gene_classifications[1:-1]\n",
    "        #yield (kmers, gene_classifications[:-1]), gene_classifications[1:]\n",
    "        #yield i[\"kmers\"], gene_classifications\n",
    "        #yield i[\"kmers\"], [gene_classifications], sample_weight\n",
    "        # yield i['kmers'], [np.average(gene_classifications)]\n",
    "\n",
    "def validation_gen():\n",
    "    fasta = pyracular.Gff3KmerGenerator(\n",
    "        k, \"Vvulg_chr2.sfasta\", window_size, \"Vvulg_chr2.gff3\", True\n",
    "    )\n",
    "    types = fasta.types()\n",
    "    gene_index = types.index(\"gene_Plus\")\n",
    "    minus_gene_index = types.index(\"gene_Minus\")\n",
    "    for i in fasta:\n",
    "        if i[\"rc\"]:\n",
    "            gi = minus_gene_index\n",
    "        else:\n",
    "            gi = gene_index\n",
    "        gene_classifications = []\n",
    "        #gene_classifications.append([1,0,0,0,0,0]) # Start token\n",
    "        gene_classifications.append(0)\n",
    "        gc_count = []\n",
    "        \n",
    "        for x in i[\"classifications\"]:\n",
    "            gc_count.append(x[gi])\n",
    "            if x[gi] == 1:\n",
    "                #gene_classifications.append([0,0,0,1,0,0]) # Is a gene\n",
    "                gene_classifications.append(3)\n",
    "            else:\n",
    "                #gene_classifications.append([0,1,0,0,0,0]) # Not a gene\n",
    "                gene_classifications.append(1)\n",
    "        total = np.sum(gc_count)\n",
    "        \n",
    "        #gene_classifications.append([0,0,0,0,0,1]) # End token\n",
    "        gene_classifications.append(5)\n",
    "\n",
    "        # TODO: Bad attempt at balancing\n",
    "        #if total == 0 or total == window_size:\n",
    "        #    continue\n",
    "\n",
    "        sample_weight = (0.5 - (np.abs((total / window_size) - 0.5))) / 0.5\n",
    "        #        if sample_weight <= 0.5:\n",
    "        #            continue\n",
    "        \n",
    "        for n in range(1, window_size+1):\n",
    "            prev = gene_classifications[n-1]\n",
    "            future = gene_classifications[n+1]\n",
    "            cur = gene_classifications[n]\n",
    "            \n",
    "            if cur == 3 and prev == 1:\n",
    "                gene_classifications[n] = 2; # Gene start\n",
    "            elif prev == 3 and future == 1:\n",
    "                gene_classifications[n] = 4\n",
    "        \n",
    "        #kmers = np.concatenate([gene_token, i['kmers'], end_of_query_token])\n",
    "        kmers = np.concatenate([cls, i['kmers']])\n",
    "        gene_classifications = tf.one_hot(gene_classifications, n_classes)\n",
    "        yield kmers, gene_classifications[1:-1]\n",
    "        #yield (kmers, gene_classifications[:-1]), gene_classifications[1:]\n",
    "        #yield i[\"kmers\"], gene_classifications\n",
    "        #yield i[\"kmers\"], [gene_classifications], sample_weight\n",
    "        # yield i['kmers'], [np.average(gene_classifications)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 105)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = validation_gen()\n",
    "next(g)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_38\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "BatchInput (InputLayer)         [(None, 33, 105)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Magic (Dense)                   (None, 33, 32)       3360        BatchInput[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "beaker (BEAKER)                 ((None, 33, 256), {' 17848048    Magic[14][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 33, 256)      0           beaker[14][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 33, 256)      1024        dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 33, 128)      32896       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 33, 128)      0           dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_12 (MultiH (None, 33, 128)      1054848     dropout_22[0][0]                 \n",
      "                                                                 dropout_22[0][0]                 \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 33, 128)      0           multi_head_attention_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 33, 128)      512         dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_24 (Sl (None, 32, 128)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 128)      512         tf.__operators__.getitem_24[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 32, 5)        645         batch_normalization_15[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 18,941,845\n",
      "Trainable params: 1,089,413\n",
      "Non-trainable params: 17,852,432\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#d0 = tfkl.Dense(128, activation=\"relu\")\n",
    "bn0 = tfkl.BatchNormalization()\n",
    "bn1 = tfkl.BatchNormalization()\n",
    "bn2 = tfkl.BatchNormalization()\n",
    "\n",
    "drop0 = tfkl.Dropout(0.15)\n",
    "drop1 = tfkl.Dropout(0.15)\n",
    "drop2 = tfkl.Dropout(0.15)\n",
    "drop3 = tfkl.Dropout(0.15)\n",
    "\n",
    "mha0 = tfkl.MultiHeadAttention(8, 256, 256, dropout=0.15)\n",
    "\n",
    "#lstm0 = tfkl.Bidirectional(tfkl.LSTM(128, return_sequences=True))\n",
    "#lstm1 = tfkl.Bidirectional(tfkl.LSTM(128, return_sequences=True))\n",
    "#conv1d = tf.keras.layers.Conv1D(256, 5, padding='same')\n",
    "d0 = tfkl.Dense(128, activation=\"relu\")\n",
    "d1 = tfkl.Dense(5, activation=\"softmax\")\n",
    "\n",
    "batch_input = Input(shape=(window_size+1, k * 5), dtype=\"float32\", name=\"BatchInput\")\n",
    "contexts = magic(batch_input)\n",
    "enc_outputs, _, _ = transformer(contexts, True)\n",
    "#x = tf.concat([enc_outputs[:,1:], contexts[:,1:]], axis=2)\n",
    "\n",
    "x = drop1(d0(bn0(drop0(enc_outputs))))\n",
    "x = bn1(drop2(mha0(x, x, x)))\n",
    "\n",
    "y = d1(bn2(x[:,1:]))\n",
    "\n",
    "#y = d1(d0(conv1d(x)))\n",
    "\n",
    "#y = d1(lstm0(d0(enc_outputs[:,1:])))\n",
    "#y = d1(l(d0(enc_outputs)))\n",
    "#y = classification(classifier(tf.concat([enc_outputs, gfc_outputs], axis=-1)))\n",
    "#y = tf.squeeze(y)\n",
    "\n",
    "model = Model(inputs=[batch_input], outputs=[y])\n",
    "\n",
    "transformer.trainable = False\n",
    "#optimizer = tfa.optimizers.RectifiedAdam(lr=0.00001)\n",
    "#optimizer = tfa.optimizers.Lookahead(optimizer)\n",
    "optimizer = tfk.optimizers.Adam(1e-3)\n",
    "model = Model(inputs=[batch_input], outputs=[y])\n",
    "print(model.summary())\n",
    "model.compile(\n",
    "    metrics=[\"mae\", \"mse\", \"binary_accuracy\", \"categorical_accuracy\", tfk.metrics.TruePositives(), tfk.metrics.FalsePositives()],\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = (\n",
    "    Dataset.from_generator(gen, (tf.float32, tf.float32)) #, tf.float32))\n",
    "    .cache(\"dmel_genes_ds\")\n",
    "    .repeat(8192*64)\n",
    "    .shuffle(256)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(8)\n",
    ")\n",
    "\n",
    "vds = (\n",
    "    Dataset.from_generator(validation_gen, (tf.float32, tf.float32)) #, tf.float32))\n",
    "    .cache(\"vvulg_chr2_genes_ds\")\n",
    "    .shuffle(256)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def categorical_focal_loss(alpha, gamma=2.):\n",
    "    \"\"\"\n",
    "    Softmax version of focal loss.\n",
    "    When there is a skew between different categories/labels in your data set, you can try to apply this function as a\n",
    "    loss.\n",
    "           m\n",
    "      FL = ∑  -alpha * (1 - p_o,c)^gamma * y_o,c * log(p_o,c)\n",
    "          c=1\n",
    "      where m = number of classes, c = class and o = observation\n",
    "    Parameters:\n",
    "      alpha -- the same as weighing factor in balanced cross entropy. Alpha is used to specify the weight of different\n",
    "      categories/labels, the size of the array needs to be consistent with the number of classes.\n",
    "      gamma -- focusing parameter for modulating factor (1-p)\n",
    "    Default value:\n",
    "      gamma -- 2.0 as mentioned in the paper\n",
    "      alpha -- 0.25 as mentioned in the paper\n",
    "    References:\n",
    "        Official paper: https://arxiv.org/pdf/1708.02002.pdf\n",
    "        https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_crossentropy\n",
    "    Usage:\n",
    "     model.compile(loss=[categorical_focal_loss(alpha=[[.25, .25, .25]], gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "    \"\"\"\n",
    "\n",
    "    alpha = np.array(alpha, dtype=np.float32)\n",
    "\n",
    "    def categorical_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred: A tensor resulting from a softmax\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        # Clip the prediction value to prevent NaN's and Inf's\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "        # Calculate Cross Entropy\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "        # Calculate Focal Loss\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "\n",
    "        # Compute mean loss in mini_batch\n",
    "        return K.mean(K.sum(loss, axis=-1))\n",
    "\n",
    "    return categorical_focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvlog = tf.keras.callbacks.CSVLogger(\n",
    "   \"TransformerGenePredictionLSTM.tsv\" , separator=',', append=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_41\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "BatchInput (InputLayer)         [(None, 33, 105)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Magic (Dense)                   (None, 33, 32)       3360        BatchInput[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "beaker (BEAKER)                 ((None, 33, 256), {' 17848048    Magic[14][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 33, 256)      0           beaker[14][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 33, 256)      1024        dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 33, 128)      32896       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 33, 128)      0           dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_12 (MultiH (None, 33, 128)      1054848     dropout_22[0][0]                 \n",
      "                                                                 dropout_22[0][0]                 \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 33, 128)      0           multi_head_attention_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 33, 128)      512         dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_24 (Sl (None, 32, 128)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 128)      512         tf.__operators__.getitem_24[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 32, 5)        645         batch_normalization_15[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 18,941,845\n",
      "Trainable params: 1,089,413\n",
      "Non-trainable params: 17,852,432\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/64\n",
      "128/128 [==============================] - 155s 1s/step - loss: 0.2437 - mae: 0.0494 - mse: 0.0245 - binary_accuracy: 0.9675 - categorical_accuracy: 0.9169 - true_positives_30: 120289.7442 - false_positives_30: 8794.9535\n",
      "Epoch 2/64\n",
      "128/128 [==============================] - 149s 1s/step - loss: 0.2503 - mae: 0.0501 - mse: 0.0250 - binary_accuracy: 0.9669 - categorical_accuracy: 0.9157 - true_positives_30: 119968.3178 - false_positives_30: 9195.4651\n",
      "Epoch 3/64\n",
      "128/128 [==============================] - 149s 1s/step - loss: 0.2496 - mae: 0.0508 - mse: 0.0250 - binary_accuracy: 0.9670 - categorical_accuracy: 0.9152 - true_positives_30: 120342.9380 - false_positives_30: 8761.9767\n",
      "Epoch 4/64\n",
      "128/128 [==============================] - 149s 1s/step - loss: 0.2432 - mae: 0.0498 - mse: 0.0247 - binary_accuracy: 0.9672 - categorical_accuracy: 0.9158 - true_positives_30: 120234.1628 - false_positives_30: 8914.6822\n",
      "Epoch 5/64\n",
      "128/128 [==============================] - 148s 1s/step - loss: 0.2379 - mae: 0.0490 - mse: 0.0241 - binary_accuracy: 0.9680 - categorical_accuracy: 0.9181 - true_positives_30: 120412.4729 - false_positives_30: 8732.9690\n",
      "Epoch 6/64\n",
      "128/128 [==============================] - 148s 1s/step - loss: 0.2524 - mae: 0.0513 - mse: 0.0254 - binary_accuracy: 0.9664 - categorical_accuracy: 0.9139 - true_positives_30: 119985.5194 - false_positives_30: 9116.1628\n",
      "Epoch 7/64\n",
      "128/128 [==============================] - 149s 1s/step - loss: 0.2363 - mae: 0.0481 - mse: 0.0240 - binary_accuracy: 0.9682 - categorical_accuracy: 0.9185 - true_positives_30: 120586.8915 - false_positives_30: 8632.2093\n",
      "Epoch 8/64\n",
      "128/128 [==============================] - 146s 1s/step - loss: 0.2452 - mae: 0.0497 - mse: 0.0248 - binary_accuracy: 0.9671 - categorical_accuracy: 0.9158 - true_positives_30: 120264.1395 - false_positives_30: 8946.2636\n",
      "Epoch 9/64\n",
      "128/128 [==============================] - 148s 1s/step - loss: 0.2576 - mae: 0.0517 - mse: 0.0260 - binary_accuracy: 0.9655 - categorical_accuracy: 0.9115 - true_positives_30: 119604.0543 - false_positives_30: 9429.0233\n",
      "Epoch 10/64\n",
      "128/128 [==============================] - 148s 1s/step - loss: 0.2294 - mae: 0.0477 - mse: 0.0233 - binary_accuracy: 0.9689 - categorical_accuracy: 0.9209 - true_positives_30: 120752.0310 - false_positives_30: 8334.4806\n",
      "Epoch 11/64\n",
      "128/128 [==============================] - 148s 1s/step - loss: 0.2403 - mae: 0.0489 - mse: 0.0243 - binary_accuracy: 0.9676 - categorical_accuracy: 0.9172 - true_positives_30: 120390.5039 - false_positives_30: 8742.9845\n",
      "Epoch 12/64\n",
      " 98/128 [=====================>........] - ETA: 35s - loss: 0.2419 - mae: 0.0496 - mse: 0.0245 - binary_accuracy: 0.9674 - categorical_accuracy: 0.9169 - true_positives_30: 91548.9082 - false_positives_30: 6767.8878"
     ]
    }
   ],
   "source": [
    "optimizer = tfk.optimizers.Adam(1e-5) # 1e-4\n",
    "model = Model(inputs=[batch_input], outputs=[y])\n",
    "print(model.summary())\n",
    "model.compile(\n",
    "    metrics=[\"mae\", \"mse\", \"binary_accuracy\", \"categorical_accuracy\", tfk.metrics.TruePositives(), tfk.metrics.FalsePositives()],\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    #loss=[categorical_focal_loss(alpha=[[.01, .25, .25, .25, .25]], gamma=2)],\n",
    "    optimizer=optimizer,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds,\n",
    "    use_multiprocessing=True,\n",
    "    shuffle=False,\n",
    "    steps_per_epoch=128,\n",
    "    epochs=64)\n",
    "    #callbacks=[csvlog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tfk.optimizers.Adam(2e-5)\n",
    "model.compile(\n",
    "    metrics=[\"mae\", \"mse\", \"binary_accuracy\", \"categorical_accuracy\", tfk.metrics.TruePositives(), tfk.metrics.FalsePositives()],\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    optimizer=optimizer,\n",
    ")\n",
    "model.fit(\n",
    "    ds,\n",
    "    use_multiprocessing=True,\n",
    "    shuffle=False,\n",
    "    steps_per_epoch=128,\n",
    "    epochs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     21/Unknown - 24s 1s/step - loss: 2.4802 - mae: 0.1841 - mse: 0.1440 - binary_accuracy: 0.8256 - categorical_accuracy: 0.5641 - true_positives_28: 23554.0000 - false_positives_28: 18047.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-277191ec381d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vds = (\n",
    "    Dataset.from_generator(validation_gen, (tf.float32, tf.float32)) #, tf.float32))\n",
    "    .cache(\"vvulg_chr2_genes_ds\")\n",
    "    .batch(batch_size)\n",
    "    .prefetch(8)\n",
    ")\n",
    "\n",
    "model.evaluate(vds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
       "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1])>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(model.predict(next(iter(vds))[0]), axis=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "BatchInput (InputLayer)      [(None, 33, 105)]         0         \n",
      "_________________________________________________________________\n",
      "Magic (Dense)                (None, 33, 32)            3360      \n",
      "_________________________________________________________________\n",
      "beaker (BEAKER)              ((None, 33, 256), {'encod 17848048  \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem_2 ( (None, 32, 256)           0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32, 256)           65792     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32, 256)           525312    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 32, 5)             1285      \n",
      "=================================================================\n",
      "Total params: 18,443,797\n",
      "Trainable params: 18,440,437\n",
      "Non-trainable params: 3,360\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "transformer.trainable = True\n",
    "optimizer = tfk.optimizers.Adam(2e-5)\n",
    "print(model.summary())\n",
    "model.compile(\n",
    "    metrics=[\"mae\", \"mse\", \"binary_accuracy\", \"categorical_accuracy\", tfk.metrics.TruePositives(), tfk.metrics.FalsePositives()],\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "  2/128 [..............................] - ETA: 2:23 - loss: 0.2452 - mae: 0.0490 - mse: 0.0250 - binary_accuracy: 0.9665 - categorical_accuracy: 0.9141 - true_positives_28: 3695.0000 - false_positives_28: 286.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-10e068183de8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     epochs=16)\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#callbacks=[csvlog])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    ds,\n",
    "    use_multiprocessing=True,\n",
    "    shuffle=False,\n",
    "    steps_per_epoch=128,\n",
    "    epochs=16)\n",
    "    #callbacks=[csvlog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"bertish_16_Feb_2021_nt_genedecoder\" # /model_{epoch:04d}.ckpt\"\n",
    "latest = tf.train.latest_checkpoint(checkpoint_path)\n",
    "if latest:\n",
    "  print(\"Loading checkpoint\")\n",
    "  print(latest)\n",
    "  model.load_weights(latest).expect_partial()\n",
    "  print(\"Checkpoint loaded\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fasta = pyracular.FastaKmersGenerator(k, \"Dmel.sfasta\", 512, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for _ in range(10):\n",
    "#    x = next(fasta)\n",
    "#x = next(fasta)\n",
    "#np.shape(np.asarray(x['kmers']))\n",
    "#[x['coords'][0][0], x['coords'][-1][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x['ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmers = np.concatenate([gene_token, x['kmers']])\n",
    "kmers = np.asarray(x['kmers'])\n",
    "ctx = magic(kmers)\n",
    "enc_outputs, _, _ = transformer(np.asarray([ctx]), False)\n",
    "lam = create_look_ahead_mask(window_size+1)\n",
    "\n",
    "#query_start = np.concatenate([[[1.0,0.0,0.0,0.0,0.0,0.0]]])\n",
    "#query_start = tf.expand_dims(query_start, 0)\n",
    "#np.shape(query_start) # (65, 4)\n",
    "\n",
    "#raw_out = list()\n",
    "#dec_output = query_start\n",
    "#dec_output = tf.cast(dec_output, tf.float32)\n",
    "#for i in range(len(x['kmers'])+1):\n",
    "lam = create_look_ahead_mask(tf.shape([ctx])[1])\n",
    "y, dec_out, dec_attn = the_decoder(np.asarray([ctx]), enc_outputs, lam, training=False)\n",
    "    #dec_output = dec_output.numpy()\n",
    "    #print(y[0][-1])\n",
    "z = tf.argmax(y[0])\n",
    "    #dec_output = tf.stack([dec_output, [[tf.one_hot(z, 4)]]], axis=2)\n",
    "    #dec_output = tf.stack([dec_output, [[tf.one_hot(z, 4)]]], axis=1)\n",
    "    \n",
    "    #dec_output = np.asarray([np.vstack([dec_output[0], y[0][-1]])])\n",
    "#dec_output[0] = np.append(dec_output, y[0][-1], axis=0)\n",
    "\n",
    "#vals = dec_output[:, :, 3][0]\n",
    "#np.shape(vals)\n",
    "#px.scatter(y=vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.argmax(y, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(y=[np.asarray(y)[:, 0], np.asarray(y)[:, 1], np.asarray(y)[:, 2], np.asarray(y)[:, 3], np.asarray(y)[:, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is query start (for decoder) [1, 0, 0, 0, 0, 0]\n",
    "# 1 is not a gene [0, 1, 0, 0, 0, 0]\n",
    "# 2 is gene start [0, 0, 1, 0, 0, 0]\n",
    "# 3 is gene [0, 0, 0, 1, 0, 0]\n",
    "# 4 is end of gene [0, 0, 0, 0, 1, 0]\n",
    "# 5 is end of decoder output [0, 0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmers = np.concatenate([gene_token, x['kmers']])\n",
    "ctx = magic(kmers)\n",
    "enc_outputs, _, _ = transformer(np.asarray([ctx]), False)\n",
    "query_start = np.concatenate([[[1.0,0.0,0.0,0.0,0.0,0.0]]])\n",
    "query_start = tf.expand_dims(query_start, 0)\n",
    "dec_output = query_start\n",
    "dec_output = tf.cast(dec_output, tf.float32)\n",
    "lam = create_look_ahead_mask(tf.shape(dec_output)[1])\n",
    "y, dec_out, dec_attn = the_decoder(y, enc_outputs, lam, training=False)\n",
    "z = tf.argmax(y[0][-1])\n",
    "dec_output = tf.concat([dec_output, [[tf.one_hot(z, n_classes)]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = create_look_ahead_mask(tf.shape(dec_output)[1])\n",
    "y, dec_out, dec_attn = the_decoder(dec_output, enc_outputs, lam, training=False)\n",
    "z = tf.argmax(y[0][-1])\n",
    "dec_output = tf.concat([dec_output, [[tf.one_hot(z, n_classes)]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "reduced = reducer.fit_transform(dec_out[-1][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(x=reduced[:, 0], y=reduced[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(y=[np.asarray(raw_out)[:, 0], np.asarray(raw_out)[:, 1], np.asarray(raw_out)[:, 2], np.asarray(raw_out)[:, 3], np.asarray(raw_out)[:, 4], np.asarray(raw_out)[:, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['coords'].index((127449, 127469))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is query start (for decoder) [1, 0, 0, 0, 0, 0]\n",
    "# 1 is not a gene [0, 1, 0, 0, 0, 0]\n",
    "# 2 is gene start [0, 0, 1, 0, 0, 0]\n",
    "# 3 is gene [0, 0, 0, 1, 0, 0]\n",
    "# 4 is end of gene [0, 0, 0, 0, 1, 0]\n",
    "# 5 is end of decoder output [0, 0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = magic(np.asarray(x['kmers']))\n",
    "enc_outputs, enc_attn, _ = transformer(np.asarray([ctx]), False)\n",
    "lam = create_look_ahead_mask(65)\n",
    "#lam = tf.expand_dims(lam, 0)\n",
    "y, dec_out, dec_attn = the_decoder(query_start, enc_outputs, lam, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygen = validation_gen()\n",
    "# mygen = gen()\n",
    "# types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "testing = list()\n",
    "answers = list()\n",
    "for x in mygen:\n",
    "    testing.append(x[0])\n",
    "    answers.append(x[1])\n",
    "    i = i + 1\n",
    "    if i == batch_size:\n",
    "        print(np.sum(answers))\n",
    "        if np.sum(answers) < 10:\n",
    "            testing = list()\n",
    "            answers = list()\n",
    "            i = 0\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testing)\n",
    "# model.predict([tb[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix = dict()\n",
    "confusion_matrix[(0, 0)] = 0\n",
    "confusion_matrix[(0, 1)] = 0\n",
    "confusion_matrix[(1, 0)] = 0\n",
    "confusion_matrix[(1, 1)] = 0\n",
    "\n",
    "for i, j in enumerate(predictions):\n",
    "    # print(\"--\")\n",
    "    for z, y in enumerate(j):\n",
    "        a = y[0]  # Predicted\n",
    "        b = answers[i][0][z]  # Actual\n",
    "\n",
    "        if a < 0.5:\n",
    "            a = 0\n",
    "        else:\n",
    "            a = 1\n",
    "        confusion_matrix[(b, a)] += 1\n",
    "\n",
    "        # print(str(y[0]) + \"\\t\" + str(answers[i][0][z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = np.asarray([testing[0]])\n",
    "contexts = magic(test_input)\n",
    "enc_outputs, attn, _ = transformer(contexts)\n",
    "\n",
    "oout = orf_layer5(orf_layer4(orf_layer3(orf_layer2(orf_layer1(orf_layer(test_input))))))\n",
    "\n",
    "decoded, dattn = decoder_layer(tf.concat([contexts, oout], axis=-1), enc_outputs)\n",
    "\n",
    "# , attn = decoder_layer(contexts, enc_outputs)\n",
    "# decoder, attn = decoder_layer(contexts, enc_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = positional_encoding(256, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe[:, :32, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_attn.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_weights(dec_attn, convert_all_kmers(x[0][0]), \"decoder_layer1_block1_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_weights(dec_attn, convert_all_kmers(x[0][0]), \"decoder_layer1_block2_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_weights(dec_attn, convert_all_kmers(x[0][0]), \"decoder_layer6_block1_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_weights(dec_attn, convert_all_kmers(x[0][0]), \"decoder_layer6_block2_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dattn.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_weights(dattn, convert_all_kmers(testing[0]), \"decoder_layer1_block1_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_weights(dattn, convert_all_kmers(testing[0]), \"decoder_layer4_block1_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_weights(dattn, convert_all_kmers(testing[0]), \"decoder_layer4_block2_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_attention_weights(attention, sentence, layer):\n",
    "    fig = plt.figure(figsize=(22, 12))\n",
    "\n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "\n",
    "    for head in range(attention.shape[0])[0:8]:\n",
    "        ax = fig.add_subplot(2, 4, head + 1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap=\"viridis\")\n",
    "\n",
    "        fontdict = {\"fontsize\": 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)))\n",
    "        ax.set_yticks(range(len(sentence)))\n",
    "\n",
    "        ax.set_ylim(len(sentence) - 1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            [sentence[i] for i in range(len(sentence))], fontdict=fontdict, rotation=90\n",
    "        )\n",
    "\n",
    "        ax.set_yticklabels(\n",
    "            [sentence[i] for i in range(len(sentence))], fontdict=fontdict\n",
    "        )\n",
    "\n",
    "        ax.set_xlabel(\"Head {}\".format(head + 1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def convert_all_kmers(kmers):\n",
    "    kmers_as_str = list()\n",
    "    for x in kmers:\n",
    "        y = \"\".join(list(map(convert_letter_to_string, np.array_split(x, k))))\n",
    "        kmers_as_str.append(y)\n",
    "    return kmers_as_str\n",
    "\n",
    "\n",
    "def convert_letter_to_string(x):\n",
    "    y = np.nonzero(x)[0][0]\n",
    "    if y == 0:\n",
    "        return \"A\"\n",
    "    elif y == 1:\n",
    "        return \"T\"\n",
    "    elif y == 2:\n",
    "        return \"N\"\n",
    "    elif y == 3:\n",
    "        return \"C\"\n",
    "    elif y == 4:\n",
    "        return \"G\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = gen()\n",
    "for x in generator:\n",
    "    if np.sum(x[1]) > 0:\n",
    "        plottable = x\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in plottable:\n",
    "#    np.dot(p, weights[0][0])\n",
    "\n",
    "calculated = np.dot(plottable[0], weights[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = UMAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = reducer.fit_transform(calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(x=reduced[:, 0], y=reduced[:, 1], color=plottable[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "reduced = pca.fit_transform(calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx(\"float64\")\n",
    "input_layer = Input(shape=k * 5, dtype=\"float64\")  # shape=(k*5),\n",
    "# input_reshape = Reshape((k,5))(input_layer)\n",
    "# input_flat = Flatten(dtype=\"float64\")(input_layer)\n",
    "# layer1 = Dense(2048, activation=\"sigmoid\", dtype=\"float64\")\n",
    "# layer2 = Dense(2048, activation=tf.nn.swish, dtype=\"float64\")\n",
    "# layer3 = Dense(1024, activation=\"relu\", dtype=\"float64\")\n",
    "layer1 = Bidirectional(GRU(1024, dtype=\"float64\"))\n",
    "classifier = Dense(window_size, activation=\"softmax\", dtype=\"float64\")\n",
    "\n",
    "output = classifier(layer1(magic(input_layer)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
